#!/usr/bin/env python3

# This file is generated by Gemini-2.5 Pro, and proven to be working.
# Dependency setup:
#    pip install torch torchvision numpy

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import numpy as np
import random


# region meta-parameters setup
SEED = 42
torch.manual_seed(SEED)
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
# endregion


# region define network structure
class MLP(nn.Module):
    def __init__(self):
        super(MLP, self).__init__()
        self.layers = nn.Sequential(
            nn.Linear(784, 300),
            nn.ReLU(),
            nn.Linear(300, 100),
            nn.ReLU(),
            nn.Linear(100, 10)
        )

    def forward(self, x):
        x = x.view(-1, 784)
        return self.layers(x)
# endregion


# region downlaod MNIST dataset
print("正在下载和准备 MNIST 数据集...")
transform = transforms.ToTensor()

train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)
test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)

train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)
test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)
print("数据准备完成。")
# endregion


# region train modele
print("\n开始训练模型...")
model = MLP()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

num_epochs = 10

for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        # 前向传播
        outputs = model(images)
        loss = criterion(outputs, labels)

        # 反向传播和优化
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if (i+1) % 300 == 0:
            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')

print("模型训练完成。")
# endregion


# region evaluate modele
with torch.no_grad():
    correct = 0
    total = 0
    for images, labels in test_loader:
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    print(f'\n模型在测试集上的精度: {100 * correct / total:.2f} %')
# endregion


# region export modele weights and biases
print("\n正在导出权重和偏置到文件...")
layer_indices = [0, 2, 4]
layer_names = ["L1_784x300", "L2_300x100", "L3_100x10"]

for i, name in zip(layer_indices, layer_names):
    layer = model.layers[i]
    weights = layer.weight.data.cpu().numpy()
    biases = layer.bias.data.cpu().numpy()

    weights_flat = weights.flatten()

    weights_filename = f"weights_{name}.bin"
    biases_filename = f"biases_{name}.bin"

    weights_flat.astype(np.float32).tofile(weights_filename)
    biases.astype(np.float32).tofile(biases_filename)

    print(f"已保存: {weights_filename} (大小: {weights_flat.size} 个浮点数)")
    print(f"已保存: {biases_filename} (大小: {biases.size} 个浮点数)")
# endregion
