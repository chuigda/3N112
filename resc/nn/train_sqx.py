#!/usr/bin/env python3

# This file is generated by Gemini-2.5 Pro, and proven to be working.
# Dependency setup:
#    pip install torch numpy


import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader
import numpy as np


# region meta-parameters setup
SEED = 42
DATA_SIZE = 2000
BATCH_SIZE = 64
LEARNING_RATE = 0.05
EPOCHS = 50
# endregion


# region random seed setup
np.random.seed(SEED)
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
# endregion


# region data saver
def save_data(input_np, label_np, filename_prefix: str):
    """
    save inputs and labels tensors to two raw binary (.bin) files
    """
    inputs_path = f"{filename_prefix}_inputs.bin"
    labels_path = f"{filename_prefix}_labels.bin"

    input_np.astype(np.float32).tofile(inputs_path)
    label_np.astype(np.uint8).tofile(labels_path)

    print(f"数据已保存到 {inputs_path} 和 {labels_path}。")

# endregion


# region prepare data
x_data = (np.random.rand(DATA_SIZE, 1) - 0.5) * 4  # x :< [-2, 2]
y_data = (np.random.rand(DATA_SIZE, 1) * 6) - 1    # y :< [-1, 5]

inputs_np = np.hstack((x_data, y_data))
labels_np = (y_data >= x_data**2).astype(int).flatten()

inputs_tensor = torch.tensor(inputs_np, dtype=torch.float32)
labels_tensor = torch.tensor(labels_np, dtype=torch.long)

dataset = TensorDataset(inputs_tensor, labels_tensor)
train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)

print(f"数据准备完毕，总共 {len(dataset)} 个样本。")
print(f"输入数据的一个样本: {inputs_tensor[0].numpy()}")
print(f"对应标签: {labels_tensor[0].numpy()}")
save_data(inputs_np, labels_np, "sqx_train")
# endregion


# region define network structure
class SimpleClassifier(nn.Module):
    def __init__(self):
        super(SimpleClassifier, self).__init__()
        self.layers = nn.Sequential(
            nn.Linear(2, 16),
            nn.ReLU(),
            nn.Linear(16, 16),
            nn.ReLU(),
            nn.Linear(16, 2)
        )

    def forward(self, x):
        return self.layers(x)

    def inspect(self):
        print("\n--- Inspecting Model Parameters and Gradients ---")
        for name, param in self.named_parameters():
            if param.requires_grad:
                print(f"Parameter: {name}")
                print("  - Data:\n", param.data)
                if param.grad is not None:
                    print("  - Gradients:\n", param.grad)
                else:
                    print("  - Gradients: None")
                print("-" * 30)

    def save(self, filename_prefix: str):
        layer_indices = [0, 2, 4]
        layer_names = ["L1", "L2", "L3"]

        print(self.layers)
        for yndex, name in zip(layer_indices, layer_names):
            layer = self.layers[yndex]
            weights = layer.weight.data.cpu().numpy()
            biases = layer.bias.data.cpu().numpy()

            weights_flat = weights.flatten()

            weights_filename = f"{filename_prefix}_weights_{name}.bin"
            biases_filename = f"{filename_prefix}_biases_{name}.bin"

            weights_flat.astype(np.float32).tofile(weights_filename)
            biases.astype(np.float32).tofile(biases_filename)

            print(f"已保存: {weights_filename} (大小: {weights_flat.size} 个浮点数)")
            print(f"已保存: {biases_filename} (大小: {biases.size} 个浮点数)")


model = SimpleClassifier()
print("\n模型结构:")
print(model)
# endregion


# region save initialized but not trained model
model.save("sqx_initial")
# endregion


# region criterion and optimizer setup
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)
# endregion


# region train modele
print("\n开始训练...")

for epoch in range(EPOCHS):
    running_loss = 0.0
    for i, data in enumerate(train_loader):
        inputs, labels = data
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    if (epoch + 1) % 10 == 0:
        print(f"Epoch [{epoch+1}/{EPOCHS}], Loss: {running_loss / len(train_loader):.4f}")

print("训练完成！")
model.save("sqx_trained")
# endregion


# region evaluate modele
print("正在评估训练效果")
TEST_DATA_SIZE = 10000

test_x_data = (np.random.rand(TEST_DATA_SIZE, 1) - 0.5) * 4
test_y_data = (np.random.rand(TEST_DATA_SIZE, 1) * 6) - 1
test_inputs_np = np.hstack((test_x_data, test_y_data))
test_labels_np = (test_y_data >= test_x_data**2).astype(int).flatten()
test_inputs_tensor = torch.tensor(test_inputs_np, dtype=torch.float32)
test_labels_tensor = torch.tensor(test_labels_np, dtype=torch.long)

print(f"测试准备完毕，总共 {len(test_y_data)} 个样本。")
print(f"输入数据的一个样本: {test_inputs_tensor[0].numpy()}")
print(f"对应标签: {test_labels_tensor[0].numpy()}")
save_data(test_inputs_np, test_labels_np, "sqx_test")

model.eval()

with torch.no_grad():
    test_outputs = model(test_inputs_tensor)
    _, predicted_classes = torch.max(test_outputs, 1)
    correct_predictions = (predicted_classes == test_labels_tensor).sum().item()
    accuracy = 100 * correct_predictions / TEST_DATA_SIZE

    print(f"模型在全新测试集上的准确率为: {accuracy}%")
# endregion
